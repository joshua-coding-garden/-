import json
import os
import pickle
import torch
import time
import numpy as np
from sklearn.neighbors import NearestNeighbors 
from langchain_huggingface import HuggingFaceEmbeddings

# --- âš™ï¸ è¨­å®šå€ ---
FILE_PATHS = ["health.json", "medical.json"] 
VECTOR_STORE_PATH = "medical_rag_store_rtx5070.pkl"
BATCH_SIZE = 512 

# --- æœå°‹å¼•æ“æ ¸å¿ƒé¡åˆ¥ ---
class MedicalSearchEngine:
    def __init__(self, texts, metadatas, embeddings, embedding_func):
        self.texts = texts
        self.metadatas = metadatas
        self.embedding_func = embedding_func
        self.embeddings_np = np.array(embeddings)
        
        # å»ºç«‹ KNN
        self.knn = NearestNeighbors(n_neighbors=10, metric='cosine', n_jobs=-1)
        self.knn.fit(self.embeddings_np)

    def search(self, query, k=5):
        query_emb = self.embedding_func.embed_query(query)
        query_emb_np = np.array([query_emb])
        dists, indices = self.knn.kneighbors(query_emb_np, n_neighbors=k)
        
        results = []
        for dist, idx in zip(dists[0], indices[0]):
            results.append({
                "doc": self.metadatas[idx], 
                "score": 1 - dist
            })
        return results

def load_and_embed_files(file_paths):
    # åˆå§‹åŒ– HuggingFace Embedding (é€™è£¡åªæ˜¯ç‚ºäº† embed_documents ç”¨)
    device = "cuda" if torch.cuda.is_available() else "cpu"
    temp_embedding_model = HuggingFaceEmbeddings(
        model_name="shibing624/text2vec-base-chinese",
        model_kwargs={'device': device},
        encode_kwargs={'batch_size': BATCH_SIZE, 'normalize_embeddings': False}
    )

    all_texts = []
    all_metadatas = []
    
    print(f"ğŸ“‚ é–‹å§‹è®€å–æª”æ¡ˆ...")
    for file_path in file_paths:
        if not os.path.exists(file_path): 
            print(f"âš ï¸ æ‰¾ä¸åˆ° {file_path}ï¼Œè·³é")
            continue
            
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
            print(f"  - {file_path}: è®€å…¥ {len(data)} ç­†")
            
            for item in data:
                q = item.get('question', '').strip()
                a = item.get('answer', '').strip()
                if not q: continue
                combined_text = f"å•é¡Œ: {q}\nç­”æ¡ˆ: {a}"
                all_texts.append(combined_text)
                all_metadatas.append({"q": q, "a": a, "source": file_path})

    print(f"âš¡ å•Ÿå‹• Embedding è¨ˆç®—...")
    embeddings = temp_embedding_model.embed_documents(all_texts)
    return all_texts, all_metadatas, embeddings

# ==========================================
# ğŸ”¥ é—œéµä¿®æ”¹ï¼šé€™å°±æ˜¯æ‚¨ç¼ºå°‘çš„å‡½å¼
# ==========================================
def initialize_rag_system():
    """
    åˆå§‹åŒ– RAG ç³»çµ±ä¸¦å›å‚³ SearchEngine ç‰©ä»¶
    """
    print("ğŸ”„ [rag_core] åˆå§‹åŒ–ç³»çµ±ä¸­...")
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    # 1. è¼‰å…¥æ¨¡å‹
    print(f"ğŸ”„ [rag_core] è¼‰å…¥ Embedding æ¨¡å‹ ({device})...")
    embedding_model = HuggingFaceEmbeddings(
        model_name="shibing624/text2vec-base-chinese",
        model_kwargs={'device': device},
        encode_kwargs={'batch_size': BATCH_SIZE, 'normalize_embeddings': False}
    )

    # 2. å˜—è©¦è®€å– Pickle
    if os.path.exists(VECTOR_STORE_PATH):
        print(f"ğŸ’¾ [rag_core] è®€å–ç´¢å¼•æª”: {VECTOR_STORE_PATH}")
        with open(VECTOR_STORE_PATH, "rb") as f:
            saved_data = pickle.load(f)
        
        search_engine = MedicalSearchEngine(
            saved_data['texts'], 
            saved_data['metadatas'], 
            saved_data['embeddings'], 
            embedding_model
        )
        return search_engine
    else:
        print("âš ï¸ [rag_core] æ‰¾ä¸åˆ°ç´¢å¼•æª”ï¼Œå˜—è©¦é‡æ–°ç”Ÿæˆ...")
        texts, metadatas, embeddings = load_and_embed_files(FILE_PATHS)
        search_engine = MedicalSearchEngine(texts, metadatas, embeddings, embedding_model)
        
        # è£œå­˜æª”
        with open(VECTOR_STORE_PATH, "wb") as f:
            pickle.dump({
                'texts': texts,
                'metadatas': metadatas,
                'embeddings': embeddings
            }, f)
        return search_engine

# --- é€™è£¡è®“ rag_core.py ä¹Ÿå¯ä»¥å–®ç¨åŸ·è¡Œæ¸¬è©¦ ---
if __name__ == "__main__":
    print("é€™æ˜¯æ ¸å¿ƒæ¨¡çµ„ï¼Œæ­£åœ¨é€²è¡Œè‡ªæˆ‘æ¸¬è©¦...")
    engine = initialize_rag_system()
    res = engine.search("é ­ç—›", k=1)
    print(f"æ¸¬è©¦çµæœ: {res}")